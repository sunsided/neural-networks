# Neural Networks Evaluation

This library and set of test programs aim to evaluate the learning and usage of *multi-layer perceptron* (MLP) networks. The **Neural** library implements different differentiable and nondifferentiable activation functions and has support for different learning strategies.

## Demo programs

* XOR problem
* Handwritten digit classification

## Transfer/activation functions

* Linear
* Sigmoid
* Tanh
* Softplus
* Rectifier
* Heaviside (Step)

## Learning algorithms

* Momentum-based gradient descent with regularization

## Cost functions

* Logistic
* Sum of squared errors